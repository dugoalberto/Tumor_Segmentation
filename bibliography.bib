@article{HAVAEI201718,
title = {Brain tumor segmentation with Deep Neural Networks},
journal = {Medical Image Analysis},
volume = {35},
pages = {18-31},
year = {2017},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2016.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S1361841516300330},
author = {Mohammad Havaei and Axel Davy and David Warde-Farley and Antoine Biard and Aaron Courville and Yoshua Bengio and Chris Pal and Pierre-Marc Jodoin and Hugo Larochelle},
keywords = {Brain tumor segmentation, Deep neural networks, Convolutional neural networks, Cascaded convolutional neural networks},
abstract = {In this paper, we present a fully automatic brain tumor segmentation method based on Deep Neural Networks (DNNs). The proposed networks are tailored to glioblastomas (both low and high grade) pictured in MR images. By their very nature, these tumors can appear anywhere in the brain and have almost any kind of shape, size, and contrast. These reasons motivate our exploration of a machine learning solution that exploits a flexible, high capacity DNN while being extremely efficient. Here, we give a description of different model choices that weâ€™ve found to be necessary for obtaining competitive performance. We explore in particular different architectures based on Convolutional Neural Networks (CNN), i.e. DNNs specifically adapted to image data. We present a novel CNN architecture which differs from those traditionally used in computer vision. Our CNN exploits both local features as well as more global contextual features simultaneously. Also, different from most traditional uses of CNNs, our networks use a final layer that is a convolutional implementation of a fully connected layer which allows a 40 fold speed up. We also describe a 2-phase training procedure that allows us to tackle difficulties related to the imbalance of tumor labels. Finally, we explore a cascade architecture in which the output of a basic CNN is treated as an additional source of information for a subsequent CNN. Results reported on the 2013 BRATS test data-set reveal that our architecture improves over the currently published state-of-the-art while being over 30 times faster.}
}

@article{GORDILLO20131426,
title = {State of the art survey on MRI brain tumor segmentation},
journal = {Magnetic Resonance Imaging},
volume = {31},
number = {8},
pages = {1426-1438},
year = {2013},
issn = {0730-725X},
doi = {https://doi.org/10.1016/j.mri.2013.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0730725X13001872},
author = {Nelly Gordillo and Eduard Montseny and Pilar Sobrevilla},
keywords = {Segmentation, MRI, Brain tumor},
abstract = {Brain tumor segmentation consists of separating the different tumor tissues (solid or active tumor, edema, and necrosis) from normal brain tissues: gray matter (GM), white matter (WM), and cerebrospinal fluid (CSF). In brain tumor studies, the existence of abnormal tissues may be easily detectable most of the time. However, accurate and reproducible segmentation and characterization of abnormalities are not straightforward. In the past, many researchers in the field of medical imaging and soft computing have made significant survey in the field of brain tumor segmentation. Both semiautomatic and fully automatic methods have been proposed. Clinical acceptance of segmentation techniques has depended on the simplicity of the segmentation, and the degree of user supervision. Interactive or semiautomatic methods are likely to remain dominant in practice for some time, especially in these applications where erroneous interpretations are unacceptable. This article presents an overview of the most relevant brain tumor segmentation methods, conducted after the acquisition of the image. Given the advantages of magnetic resonance imaging over other diagnostic imaging, this survey is focused on MRI brain tumor segmentation. Semiautomatic and fully automatic techniques are emphasized.}
}

@misc{CBTRUSTumors2022,
    author = {CBTRUS - Central Brain Tumor Registry of the United States},
    title = {CBTRUS Fact Sheet},
    url = {https://cbtrus.org/cbtrus-fact-sheet/},
    accessed = {31/03/2025}
}

@misc{BraTSChallenge,
    author={Perelman School of Medicine - University of Pennsylvania},
    title={Brain Tumor Segmentatation (BraTS) Challenge},
    url = {https://www.med.upenn.edu/cbica/brats/},
    accessed = {31/05/2024}

}

@misc{BraTSdataset,
    author={Kaggle},
    title={Kaggle BraTS2020 Dataset},
    url = {https://www.kaggle.com/datasets/awsaf49/brats20-dataset-training-validation},
    accessed = {04/04/2025}

}

@InProceedings{He_2015_ICCV,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {December},
year = {2015}
}